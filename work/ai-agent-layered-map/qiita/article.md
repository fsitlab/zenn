---
title: "Claude Codeで3日間で22万文字のZenn本を書いた話"
tags:
  - claudecode
  - claude
  - LLM
  - AIエージェント
  - Zenn
---

## はじめに

先日、Zennに「[AIエージェント概念マップ：5層モデルで理解する](https://zenn.dev/)」というBookを公開しました。

- 全19章・22万文字
- 執筆期間：**実質3日間**
- 執筆ツール：**Claude Code**（AIエージェント）

「3日で22万文字？」と思われるかもしれません。
でもこれは、AIにすべて任せた手抜きではなく、**AIと人間が役割分担して本気で作った本**です。

その裏側のプロセスをまるごと公開します。

---

## なぜ本を書こうと思ったか

きっかけは、**自分の中にある生成AI知識がバラバラだった**ことです。

RAG、MCP、LangChain、Claude Code、A2A、Hooks…
毎週のように新しい概念が登場する中で、「これって結局、何をしているのか？」が曖昧なまま記事を読んでいました。

頭の中に概念の断片はある。でも**地図がない**。

「自分のために、知識を整理した地図を作ろう」
それが出発点でした。

---

## 本になるまでの7ステップ

### Step 1：Claudeと会話して骨子を作成

最初はClaude（ブラウザ版）との対話から始まりました。
「生成AIの概念を体系的に整理したい」という曖昧なゴールを投げ、**何度もやりとりを重ねながら骨子を作成**しました。

この段階では「ざっくりこういうことを書きたい」という方向性が固まりました。

### Step 2：骨子をブラッシュアップ

初期の骨子をさらに深掘り。
「この概念はどの層に属するか」「この概念とあの概念の違いは何か」を一つひとつ確認していきました。

### Step 3：トークン切れの待ち時間に「5層モデル」を思いつく

ここが転換点でした。

AIとの会話が長くなり、**トークン上限に引っかかって待ち時間**が発生。
その間にぼんやり考えていたところ、ふと気づきました。

「生成AIの概念って、**層ごと**に整理できるんじゃないか？」

```
第1層：LLM層（モデル自体）
第2層：通信層（APIのやりとり）
第3層：LLMオーケストレーション層（LLMを操るアプリ）
第4層：外部ツール層（MCPサーバー、RAG等）
第5層：UI・運用層（ユーザーが触る部分）
```

この**5層モデル**という構造が決まった瞬間、「これは記事じゃなくて本になる」と確信しました。

### Step 4：5層モデルで執筆開始（Claude Code登場）

ここからClaude Codeが主役になります。

まず**初期プロンプト**で全体設計を伝えました（実際のプロンプトの一部）：

```
本フォルダにある複数のMDファイルを統合して、1個の記事にしたい。
ただし、１個のファイルへの出力は長くなりすぎるので、
アウトプット用のパスに各章単位で分割したMDファイルを作成して。


## アウトプット形式
かなり長大なレポートになるので、アウトプットは章ごとにmdファイル分けて。

./work/ に、ワーク中の中間ファイルを保存して。
./work/memo.mdなどに、 各Agentが作業中に気づいた内容をメモファイルとして残して。
./work/plan.md に作業計画を残して。
成果物は、
./output/ に章ごとにMDファイルを分けて書いて。 

## タスクの進め方

Agent Teamsでタスクを処理して。
まずは、タスク計画を立てて。何をすべきか整理して。
その後、並列可能な個所は並列処理して記事を書いて。
その後、ハルシネーションがないかチェックするエージェントは、嘘を検知して。
また、各章の整合性が取れているか、校閲するエージェントは校閲して。
検知した嘘や、校閲内容は、./work/review.mdなどにに保存して。
その後、この修正内容をみて、出力結果をブラッシュアップして。

## 制約事項
・元ファイルを編集してはいけない。新規ファイルを作成して。
・中間ファイルも削除は禁止。不要になったら、その階層に/oldフォルダを作ってそこに移動して。
```

Claude Codeは**並列でサブエージェントを立ち上げ**、各章を同時に執筆し始めました。

```
作業中のタスク（並列実行）:
- Task 5: 01_LLM層.md作成
- Task 6: 02_通信層.md作成
- Task 7: 03_アプリ層.md作成
- Task 8: 04_外部ツール層.md作成
- Task 9: 05_プレゼンテーション層.md作成
- Task 10: 06_早見表.md作成
...（同時進行）
```

私がやることは、**上がってくる成果物を確認してコメントするだけ**。

### Step 5：FactチェックAgent・整合性チェックAgentに検証させる

執筆が一段落したら、今度は**検証フェーズ**です。

**FactチェックAgent**：各層ごとに並列で走らせ、事実誤認を検知

実際に見つかった誤りの例（`review.md`より）：

| # | 問題の種類 | 詳細 |
|---|-----------|------|
| Hooksイベント数 | 事実誤り | 4種類のみ記載 → 実際は12種類 |
| SubagentStartのブロック可否 | 事実誤り | 「ブロック可能」→ 正しくは「ブロック不可」|
| Anthropic URL参照 | 事実誤り | 「非対応」→ 2025年に対応済み |
| Gemini WebSocket | 事実誤り | 「非対応」→ Live APIで対応済み |
| Kiro Specs構成 | 事実誤り | 4要素 → 正しくは3ファイル |

**整合性チェックAgent**：各章間の矛盾を洗い出し

```
発見した問題（整合性チェック結果）:
- 04_c_Claude設定ファイル.md: 旧ファイル名への参照が残存
- 04_b_エージェント連携.md: 「構造化I/O層」（古い名称）が残存
- モデル名表記ゆれ: claude-sonnet-4-6 と claude-sonnet-4-20250514 が混在
- 07_Claude_Cowork.md と 07_f_その他製品.md でコンテンツが重複
```

これをやらずに公開していたら、かなりの誤情報が残っていたでしょう。

### Step 6：人間とAIが協力して修正

Factチェック・整合性チェックの結果は、すべて`work/review.md`に蓄積。

修正は2パターン：

**AIによる修正**：明確な事実誤りや表記ゆれはAIが直接修正

**私による修正コメント**：判断が必要なものは`review.md`に書き込んで方針を伝える

```markdown
# review.mdへの私のコメント（実際の書き込み）

##　早見表の強化
６章の早見表に索引機能を持たせたい。
階層構造だけじゃなくて、本文で解説した章番号を追加するカラムをつくって

## セキュリティの検討不足
OWASP LLM Top 10 (2025) の5層マッピングについて、
なぜその層なのか、明示するため、最初から表を書かずに、
1個１個、そのリスクが起こるフロー図を5層モデルのマーメード図で示して
```

このコメントを読んだClaude Codeが、再度修正を実施。
このループを数回繰り返しました。

### Step 7：Qiitaは断念、Zennへ

完成した原稿は**全19章・22万文字**。

Qiitaに投稿するには、長すぎる記事が完成しました。
そこで、**Zennのチャプター分割形式（Book）にすることで解決**しました。

---

## 3日でできた理由

### 理由①：章を分割してAIを並列実行した

これが最大の理由です。

通常の執筆では「第1章を書いてから第2章へ」と直列で進みます。
でも**章を独立したMDファイルに分けることで、Claude Codeが並列でサブエージェントを立ち上げ、複数章を同時に執筆できました**。

```
第1章を書く Agent ─┐
第2章を書く Agent ─┤
第3章を書く Agent ─┼─→ 並列実行
第4章を書く Agent ─┤
...                ─┘
```

さらに検証フェーズも同じ構造で並列化：

```
第1層 Factチェック Agent ─┐
第2層 Factチェック Agent ─┤
第3層 Factチェック Agent ─┼─→ 並列実行
第4層 Factチェック Agent ─┤
第5層 Factチェック Agent ─┘
```

私がやることは、次々と上がってくる成果物を見ながら、`review.md`にコメントを書き込むことです。

### 理由②：最初に骨格（5層構造）を作ったのが良かった

「何を書くか」の構造が固まっていれば、あとはAIが肉付けできます。

逆に言えば、**構造が曖昧なまま「書いて」と頼んでも、バラバラなものが出てくる**だけです。

今回は「5層モデル」という一貫したフレームワークがあったので、各章がそのフレームに沿って書かれ、自然と整合性が取れました。

### 理由③：workフォルダで人間もAIもメモを残せる構造を作った

```
work/
├── plan.md          # 作業計画（AI記入）
├── memo.md          # 作業メモ（AI記入）
├── review.md        # レビュー・指示（人間 + AI 混在）
├── review/          # レビュー履歴アーカイブ
├── prompt/          # 使ったプロンプトの保存
│   ├── 初期プロンプト.txt
│   ├── レビュープロンプト.txt
│   └── レビュー後修正プロンプト/
├── layer1_fact_check.md  # 各層のfactチェック結果
├── layer2_fact_check.md
...
output/              # 成果物（章ごとのMD）
```

この`work/`ディレクトリが**AIと人間の共有作業台**になりました。

- AIは実行中の気づきを`memo.md`に記録
- 人間（私）はレビューコメントを`review.md`に記入
- 次に立ち上げたAIが`review.md`を読んで続きを引き継ぐ

**セッションをまたいでコンテキストが引き継がれる**のが大きなポイントです。

---

## 完成した本の内容（ちょっと紹介）

https://zenn.dev/fsitlab/books/ai-agent-layered-map

生成AIに関わる様々な概念（RAG、MCP、LangChain、Hooks、A2A、サブエージェント…）を、5層モデルで整理したガイドです。

| 章 | 内容 |
|----|------|
| 第1層：LLM層 | モデルの種類、LoRA、Constitutional AI |
| 第2層：通信層 | OpenAI/Anthropic/Gemini APIの比較、プロンプト技術 |
| 第3層：LLMオーケストレーション層 | LangChain、Hooks、ワークフロー |
| 第4層：外部ツール層 | MCP、RAG（従来型 vs Tool型）、A2A、サブエージェント |
| 第5層：UI・運用層 | VSCode、Dify、監視・ログ |
| 早見表（6章） | 各製品がどの層に属するか |
| 製品解説（7章） | Claude Code、Cursor、Dify、ChatGPT、Kiro等を5層で解説 |
| 相性問題（8章）|　なぜ相性問題が起きるか、５層構造で解説　|
| セキュリティ(9章) | OWASP LLM Top 10 (2025)を5層にマッピング |
| 付録（10章）|　リンク集など | 

---

## やってみての気づき

**良かった点：**
- 「自分が整理したいから書く」という動機だと、AIへの指示が具体的になる
- 章単位の並列実行が効いた。体感で3〜4倍速
- workフォルダによるコンテキスト引き継ぎで、セッション断絶の影響が最小化
- FactチェックAgentが思った以上に誤りを見つけてくれた

**難しかった点：**
- 構造設計（5層モデルの定義）は人間がしっかり考える必要がある
- AIが書いた内容の品質チェックは自分でやる必要がある（完全放置はNG）
- 層の定義が曖昧だと章間の整合性が崩れる。最初の定義が大事

**意外だったこと：**
- Qiitaが長すぎて投稿できなかった（22万文字...）
- FactチェックAgentが事実誤りを複数発見。「AIが書くから正確」は幻想

---

## まとめ

| 項目 | 内容 |
|------|------|
| 執筆期間 | 3日間（実働） |
| 文字数 | 約22万文字 |
| 使用ツール | Claude Code |
| 工夫 | 章の並列執筆 / Factチェックの並列検証 / workフォルダ共有 |

**Claude Codeは「書いてくれるツール」じゃなくて「一緒に作るパートナー」**です。
構造を考えて、指示を出して、レビューして、方針を決める——これは人間の仕事。
それ以外の実行部分をAIが担う。

そのスタイルで作ったのがこの本です。

本はZennで無料公開しています。生成AI概念の整理に役立てていただければ嬉しいです。

---

今回本を執筆したプロジェクトフォルダは、以下Githubに公開しています。

https://github.com/fsitlab/zenn/tree/main/work/ai-agent-layered-map